---
title: 'Taller: Fortalecimiento del capital humano y herramientas analíticas en torno
  al monitoreo de aves playeras en Chile'
author: "Red de Observadores de Aves y Vida Silvestre de Chile"
output:
  html_document: default
  word_document: default
  pdf_document: default
---


## Introducción

Las aves playeras son un grupo que enfrenta numerosos amenazas a lo largo de su distribución y que ha mostrado declives preocupantes en sus poblaciones en la mayoría de las especies. Diversos esquemas de monitoreo se efectuan actualmente con una extensa cobertura geográfica, sin embargo las capacidades analíticas para analizar y utilizar estos datos para la toma de decisiones es frecuentemente un piedra de tope. Para promover y facilitar el analisis de datos de conteo de aves playeras, desarrollamos un código fácil de ejecutar para estimar abundancias y tendencias de aves playeras utilizando datos del Migratory Shorebirds Project (MSP), Censo Neotropical de Aves Acuáticas (CNAA) y Censo Costero de Aves Playeras (CCAP). 

Presentamos un modelo simple, utilizando datos recolectados en Chile desde el 2009 al 2025. Este modelo es facilmente replicable con otros datos, ya sea de una región más acotada o bien una más amplia. Desarrollamos este modelo para ser útil para estimar abundancia y tendencias en cualquier país o región que cuenten con esquemas de monitoreo estandarizados. Adicionalmente, el modelo es fácilmente extendido para incluir variables fijas o aleatorias que sean de interés de acuerdo a cada situación.

##
Para comenzar, debemos cargar las librerias que ocuparemos y los diferentes archivos con los que trabajaremos, para luego preparar las bases de datos de los diferentes esquemas de monitoreo. 
En este flujo dejaremos como ejemplo la preparación de la base de datos de MSP. Las bases de datos de los otros dos esquemas de monitoreo están preparadas y cargadas en el repositorio (CCAPver.rda y CNAAver.rda). Estas están en el formato que se requiere para trabajar con el paquete spAbundance. Ver Doser et al. 2023 para más detalles del paquete.

```{r librerias y archivos}
# Cargar librerias y archivos necesarios para ejectuar el modelo
library(abind)
library(corrplot)
library(dplyr)
library(ggforce)
library(ggplot2)
library(grid)
library(gridExtra) 
library(lubridate)
library(MCMCvis)
library(purrr)
library(reshape2)
library(scales)
library(spAbundance)
library(tidyr)
library(writexl)


# Cargar datos
df <- read.csv("MSPabr2025.csv", header = TRUE) #Base de datos de MSP
df.u <- read.csv('UnidadesMSP.csv') #Base de datos con el detalle de los sitios MSP
df.a <- read.csv('AvesChile.csv') #Base de datos de las aves presentes en Chile

load("CCAPver.rda") #Base de datos del Censo Costero de Aves Playeras preparado
load("CNAAver.rda") #Base de datos del Censo Neotropical de Aves Acuáticas preparado

# Revisión de los archivos cargados
str(df)
str(df.u)
str(df.a)
str(CCAPver)
str(CNAAver)
```

## Preparación base de datos MSP

Para este ejemplo, trabajaremos con los datos registrados durante los censos realizados en la temporada verano y comenzaremos por identificar los sitios con sus respectivas fechas de censos y el total de especies observadas en todos los años para rellenar la matriz de conteo con zeros para las especies no observadas por censo.

```{r preparación bd MSP}
df$Date <- as.Date(df$Date) #Transformar columna Date a formato fecha

# Seleccionar columnas relevantes para acotar tamaño del objeto
df <- df %>%
  select(Sampling.Unit.Name, Start.Time, End.Time, Spp, Common.Name,
         Scientific.Name, Count, Date)

# Filtrar los datos a la temporada que trabajaremos (en este caso entre diciembre y marzo para temporada de verano austral)
ds.ver <- df %>% filter(month(Date) <= 3 | month(Date) >= 12) 

# Definir especies de verano
especies.ver <- ds.ver %>% 
  filter(Spp != "---") %>% 
  select(Spp, Common.Name, Scientific.Name) %>%
  distinct()

# Identificar las filas con '---' en el código de la especie (censos sin observaciones)
censos_sin_obs.ver <- ds.ver %>%
  filter(Spp == "---")

# Generar nuevas filas para censos sin observaciones
nuevas_filas <- map_df(1:nrow(censos_sin_obs.ver), function(i) {
  fila_actual <- censos_sin_obs.ver[i,]
  
  especies_observadas <- ds.ver %>%
    filter(Sampling.Unit.Name == fila_actual$Sampling.Unit.Name & 
             Spp != "---") %>%
    select(Spp) %>%
    distinct() %>%
    left_join(especies.ver, by = "Spp")
  
  especies_observadas %>%
    mutate(Count = 0,
           Date = fila_actual$Date,
           Sampling.Unit.Name = fila_actual$Sampling.Unit.Name,
           Start.Time = fila_actual$Start.Time,
           End.Time = fila_actual$End.Time,
           SiteName = fila_actual$SiteName,
           Researcher = fila_actual$Researcher,
           Other.Observers.Count = fila_actual$Other.Observers.Count,
           nresearcher = fila_actual$nresearcher,
           Ha = fila_actual$Ha,
           lha = fila_actual$lha)
})

# Combinar datos originales y nuevas filas
ds.ver2 <- ds.ver %>%
  filter(Spp != "---") %>%
  bind_rows(nuevas_filas)

# Añadir columna presencia/ausencia
ds.ver2$presencia <- ifelse(ds.ver2$Count > 0, 1, 0)

# Combinaciones de especie y unidad de muestreo según observaciones
combinaciones <- ds.ver2 %>%
  select(Spp, Sampling.Unit.Name) %>%
  distinct()

# Identificar fechas de censos en cada unidad de muestreo
fechas.censos <- ds.ver2 %>%
  select(Sampling.Unit.Name, Date) %>%
  distinct()

# Combinar especies con fechas de censos para cada unidad de muestreo
combinaciones_expandidas <- left_join(combinaciones, fechas.censos, by = "Sampling.Unit.Name", relationship = "many-to-many")

# Unión con datos originales para completar las ausencias
ds.ver.compl <- left_join(combinaciones_expandidas, ds.ver2, by = c("Spp", "Sampling.Unit.Name", "Date"))%>%
  replace_na(list(presencia = 0))

# Corrección de valores asociados a `Date`:
info_date <- ds.ver2 %>%
  filter(!is.na(Start.Time) & !is.na(End.Time)) %>%
  select(Sampling.Unit.Name, Date, Start.Time, End.Time) %>%
  distinct()

ds.ver.compl <- left_join(ds.ver.compl, info_date, by = c("Sampling.Unit.Name", "Date"))

# Sobrescribimos las columnas originales con las columnas provenientes de info_date y luego las eliminamos
ds.ver.compl$Start.Time.x <- ds.ver.compl$Start.Time.y
ds.ver.compl$End.Time.x <- ds.ver.compl$End.Time.y
ds.ver.compl <- ds.ver.compl %>% select(-Start.Time.y, -End.Time.y)

# Corrección de valores asociados a `Spp`:
info_spp <- ds.ver2 %>%
  select(Spp, Common.Name, Scientific.Name) %>%
  distinct()

ds.ver.compl <- left_join(ds.ver.compl, info_spp, by = "Spp")

# Sobrescribimos las columnas originales con las columnas provenientes de info_spp y luego las eliminamos
ds.ver.compl$Common.Name.x <- ds.ver.compl$Common.Name.y
ds.ver.compl$Scientific.Name.x <- ds.ver.compl$Scientific.Name.y
ds.ver.compl <- ds.ver.compl %>% select(-Common.Name.y, -Scientific.Name.y)

ds.ver.compl <- ds.ver.compl %>% 
  rename_with(~ gsub("\\.x$", "", .x))

# Registro único por especie, unidad de muestreo y fecha
MSPver <- ds.ver.compl %>%
  group_by(Spp, Sampling.Unit.Name, Date) %>%
  summarise(across(everything(), first)) %>%
  distinct()  

# Reemplazar NA con 0 en la columna Count para las ausencias
MSPver$Count <- replace_na(MSPver$Count, 0)

MSPver <- MSPver %>%
  select(Sampling.Unit.Name, Start.Time, End.Time, Spp, Common.Name,
         Scientific.Name, Count, Date)

MSPver <- left_join(MSPver, df.u, by = "Sampling.Unit.Name")

# Añadir columna de año a los datos
MSPver <- MSPver %>%
  mutate(year = year(Date))

# Crear la matriz binaria de réplicas y ordenar los años
matriz_binaria <- MSPver %>%
  group_by(Sampling.Unit.Name, year) %>%
  summarise(replicas = n(), .groups = 'drop') %>%
  pivot_wider(names_from = year, values_from = replicas, values_fill = 0) %>%
  mutate(across(-Sampling.Unit.Name, ~ ifelse(. > 0, 1, 0)))

# Obtener los nombres de las columnas y ordenar los años
columnas_ordenadas <- c("Sampling.Unit.Name", sort(names(matriz_binaria)[-1]))

# Reordenar las columnas
matriz_binaria <- matriz_binaria %>%
  select(all_of(columnas_ordenadas))

# Función para verificar si hay al menos tres ceros en la fila
tiene_una_replica <- function(x) {
  sum(x == 0) >= 6
}

# Crear una tabla con las fechas por unidad de muestreo en cada año
fechas_por_unidad <- MSPver %>%
  group_by(Sampling.Unit.Name, year) %>%
  summarise(fechas = list(as.character(unique(Date))), .groups = 'drop')

MSPver <- MSPver %>%
  select(SiteName, Sampling.Unit.Name, Spp,Scientific.Name, Count, Date, Longitude, 
         Latitude, Ha)

MSPver$Date <- as.Date(MSPver$Date, format = "%Y-%m-%d")

# Durante el año 2020 y 2021 las fechas están corridas. Modificaremos para que las tempradas queden unificadas con las de los otros años
# Modificar las fechas para el año 2021
MSPver <- MSPver %>%
  mutate(Date = case_when(
    year(Date) == 2021 ~ as.Date("2021-02-15"),
    TRUE ~ Date
  ))

# Modificar las fechas para dic 2020
MSPver <- MSPver %>%
  mutate(Date = case_when(
    Date == "2020-12-15" ~ as.Date("2021-02-15"),
    TRUE ~ Date
  ))

MSPver <- MSPver %>%
  mutate(Date = ymd(Date), 
         year = year(Date)) 

# En el caso de tener más de una réplica de censo en algún año optamos por hacer uso de los datos adicionales y promediarlos. Opcionalmente podrían usar una opción menos conservadora y mantener solo el valor máximo entre las réplicas
# Para sitios con múltiples fechas en 2021, promediamos
MSPver <- MSPver %>%
  group_by(Sampling.Unit.Name, Spp, Date) %>%
  summarise(
    Count = round(mean(Count, na.rm = TRUE)),
    year = first(year),
    SiteName = first(SiteName),
    Scientific.Name = first(Scientific.Name),
    Spp = first(Spp),
    .groups = "drop"
  )

MSPver$Count <- as.numeric(MSPver$Count)

# Crear la columna "SitioAño" combinando la información de "SiteName" y "year"
MSPver$SitioAño <- paste(MSPver$SiteName, MSPver$year, sep = ".")

df.a <- df.a %>%
  select(Scientific.Name, Orden.taxonómico)

MSPver <- left_join(MSPver, df.a, by = "Scientific.Name")

MSPver$Orden.taxonómico <- as.numeric(MSPver$Orden.taxonómico)

#Sacar datos de Rocuant3 del año 2022, ya que solo hay información de esa unica unidad
MSPver <- MSPver %>%
  filter(!(Sampling.Unit.Name == "ROCUANT3" & year == 2022))

## Ausencias HUGO Coquimbo (2022-2025)

# Extraer una unidad de muestreo del sitio "Coquimbo" para saber qué info replicar
unidad_ref <- MSPver %>%
  filter(Sampling.Unit.Name == "COQ20") %>%
  slice(1)

# Crear las 4 filas para la especie HUGO con Count = 0
nuevas_ausencias <- tibble(
  SiteName = "Coquimbo",
  Sampling.Unit.Name = unidad_ref$Sampling.Unit.Name,  # Usamos una unidad representativa
  Spp = "HUGO",
  Count = 0,
  Date = as.Date(c("2022-02-14", "2023-02-15", "2024-02-15", "2025-02-08")),
)

# Agregar el año
nuevas_ausencias <- nuevas_ausencias %>%
  mutate(year = year(Date))

# Agregar estas ausencias a MSPver
MSPver <- bind_rows(MSPver, nuevas_ausencias)


# Filtrar solo las especies de aves playeras
# Para esto es necesario determinar el valor minimo y máximo de la "primera" y "última" especie de ave playera en sus datos según el orden taxonómico. La base de datos de eBird cuenta con una columna, "Orden.taxonómico", con un número único por especie.
MSPver <- MSPver %>%
  filter(Orden.taxonómico >= 99 & Orden.taxonómico <= 161)

#Sacamos de este análisis los sitios nuevos 2025
MSPver <- MSPver %>%
  filter(!is.na(SiteName))

# Obtener la lista completa de "SitioAño",los años y especies
all_UA <- unique(MSPver$SitioAño)
all_years <- unique (MSPver$year)
all_sp <- unique (MSPver$Scientific.Name)

# Preparación de la base de datos MSP en el formato que pide spAbundance, a nivel de sitio
MSPverSitios <- MSPver %>%
  group_by(SitioAño, Scientific.Name, year) %>%
  summarise(Count = sum(Count, na.rm = TRUE), .groups = 'drop')


# Crear la matriz de conteo
y <- matrix(NA, nrow = length(all_sp), ncol = length(all_UA))
rownames(y) <- all_sp
colnames(y) <- all_UA

# Llenar la matriz con los valores de conteo "Count"
for (i in 1:nrow(MSPverSitios)) {
  UA <- MSPverSitios$SitioAño[i]
  sp <- MSPverSitios$Scientific.Name[i]     
  count <- MSPverSitios$Count[i]
  
  row_index <- match(sp, all_sp)
  col_index <- match(UA, all_UA)
  
  y[row_index, col_index ] <- count
}

media_year <- mean(MSPverSitios$year)
desviacion_year <- sd(MSPverSitios$year)
MSPverSitios$years <- (MSPverSitios$year - media_year) / desviacion_year


# Crear la matriz de año
año <- matrix(NA, nrow = length(all_UA), ncol = 1)
rownames(año) <- all_UA
colnames(año) <- "año"

# Llenar la matriz con los valores de año
for (i in 1:nrow(MSPverSitios)) {
  UA <- MSPverSitios$SitioAño[i]
  year_value <- MSPverSitios$year[i]  
  
  row_index <- match(UA, all_UA)
  
  año[row_index, ] <- year_value  
}


# Crear el objeto covs como una lista
covs <- list(
  "año" = año
  )

# Base de datos 
MSPver <- list(y = y,
            covs = covs)
# Revisamos
str(MSPver)


save(MSPver, file = 'MSPver.rda')
```

## Preparación base de datos unificada 

En el caso de contar con datos de más de un esquema de monitoreo, repetir el paso anterior de preparación de datos para cada esquema.

Ahora que tenemos preparadas las bases de datos con las que trabajaremos, debemos unificarlas y dejarlas en el formato requerido por el paquete spAbundance.

Un punto importante a considerar es que al únificar datos de más de un esquema solo es posible incluir especies que estén presentes en todos los esquemas. Para analizar los datos de todas las especies en cada esquema se debe analizar los datos de forma separada.

```{r preparación base de datos unificada}
# Obtener nombres de las especies
especies_CNAA <- rownames(CNAAver$y)
especies_CCAP <- rownames(CCAPver$y)
especies_MSP  <- rownames(MSPver$y)

# Especies presente en los tres esquemas de monitoreo
especies_comunes <- Reduce(intersect, list(especies_CNAA, especies_CCAP, especies_MSP))

# Filtrar las matrices por especies comunes (filas)
CNAAver$y <- CNAAver$y[especies_comunes, , drop = FALSE]
CCAPver$y <- CCAPver$y[especies_comunes, , drop = FALSE]
MSPver$y  <- MSPver$y[especies_comunes,  , drop = FALSE]

all_rownames <- unique(c(rownames(CNAAver$y), 
                         rownames(CCAPver$y), 
                         rownames(MSPver$y)))

# Expandir matrices para que tengan todas las filas
expand_matrix <- function(mat, all_rownames) {
  expanded_mat <- matrix(NA, nrow = length(all_rownames), ncol = ncol(mat), 
                         dimnames = list(all_rownames, colnames(mat)))
  expanded_mat[rownames(mat), colnames(mat)] <- mat
  return(expanded_mat)
}

CNAA_y <- expand_matrix(CNAAver$y, all_rownames)
CCAP_y <- expand_matrix(CCAPver$y, all_rownames)
MSP_y  <- expand_matrix(MSPver$y,  all_rownames)

# Obtener todos los sitio.año 
all_colnames <- unique(c(colnames(CNAA_y), colnames(CCAP_y), colnames(MSP_y)))

# Expandir columnas para que todas las matrices tengan todos los sitioaño
expand_cols <- function(mat, all_colnames) {
  expanded_mat <- matrix(NA, nrow = nrow(mat), ncol = length(all_colnames),
                         dimnames = list(rownames(mat), all_colnames))
  expanded_mat[, colnames(mat)] <- mat
  return(expanded_mat)
}

CNAA_y <- expand_cols(CNAA_y, all_colnames)
CCAP_y <- expand_cols(CCAP_y, all_colnames)
MSP_y  <- expand_cols(MSP_y,  all_colnames)

# Identificar y guardar los NA previos a la unión
na_CNAA <- is.na(CNAA_y)
na_CCAP <- is.na(CCAP_y)
na_MSP  <- is.na(MSP_y)

# Sumar matrices (mismo sitioaño-especie puede estar en varios esquemas)
CNAA_y[is.na(CNAA_y)] <- 0
CCAP_y[is.na(CCAP_y)] <- 0
MSP_y[is.na(MSP_y)] <- 0

y_combined <- CNAA_y + CCAP_y + MSP_y

all_na <- na_CNAA & na_CCAP & na_MSP
# Mantener los NA originales
y_combined[all_na] <- NA

# Filas = especies, Columnas = sitio.año
conteo_por_especie <- rowSums(!is.na(y_combined))
total_por_especie <- rowSums(y_combined, na.rm = TRUE)

# En este modelo optamos por incluir solo las especies con mayor representatividad y abundancia en los sitios censados para maximizar la robustes de los resultados. Especies con muy pocos registros o abundancia baja serán dificiles de estimar su abundancia con un rango aceptable de error.

# Evaluaremos el top 10 de las especies según presencia en sitios-años (cantidad de registros x especie)
sort(conteo_por_especie, decreasing = TRUE)[1:10]

# Evaluaremos el top 10 de las especies según el total de individuos registrados (cantidad de individuos x especie) 
sort(total_por_especie, decreasing = TRUE)[1:10]

# Según la evaluación previa, seleccionamos las especies que presentan más de 100 registros
especies_filtradas <- names(conteo_por_especie[conteo_por_especie >= 100])
# Este filtro resulta en 6 especies que a modo de ejemplo trabajaremos en este taller:
# Haematopus palliatus, Numenius phaeopus, Limosa haemastica, Tringa flavipes, Tringa melanoleuca y Calidris bairdii
y_filtrado <- y_combined[especies_filtradas, ]

# Extraer sitio y año
site_names <- colnames(y_filtrado)
sitios <- sub("\\..*", "", site_names)
year <- as.numeric(sub(".*\\.", "", site_names))
names(year) <- site_names 

# Crear variable esquema
MSP.ind  <- as.numeric(colnames(y_filtrado) %in% colnames(MSPver$y))
CNAA.ind <- as.numeric(colnames(y_filtrado) %in% colnames(CNAAver$y))
CCAP.ind <- as.numeric(colnames(y_filtrado) %in% colnames(CCAPver$y))

# Lista de covariables
covs <- list(
  MSP  = MSP.ind, #Agregamos el esquemas como covariable, con valor de 0 y 1, donde 1 indica que ese dato proviene del esquema
  CNAA = CNAA.ind, #Agregamos el esquemas como covariable, con valor de 0 y 1, donde 1 indica que ese dato proviene del esquema
  CCAP = CCAP.ind, #Agregamos el esquemas como covariable, con valor de 0 y 1, donde 1 indica que ese dato proviene del esquema
  year = year
)

# Lista final para el modelo
data_list <- list(
  y = y_filtrado,
  covs = covs
)

# Tenemos la base de datos preparada. Los siguientes pasos fueron agregados para evitar problemas en la ejecución del modelo
# Convertir todas las covariables a matrices columna con nombres consistentes
for (i in seq_along(data_list$covs)) {
  covariate <- data_list$covs[[i]]
  if (is.null(dim(covariate))) {
    mat <- matrix(covariate, ncol = 1)
    colnames(mat) <- names(data_list$covs)[i]
    rownames(mat) <- site_names 
    data_list$covs[[i]] <- mat
  }
}

# Conservar los nombres de fila (especies), quitar nombres de columnas en y
rownames(data_list$y) <- rownames(data_list$y)
colnames(data_list$y) <- NULL
data_list$covs <- lapply(data_list$covs, function(x) {
  dimnames(x) <- NULL
  return(x)
})

# Crear un vector con los nuevos códigos, para dejar en la base de datos final los códigos
species_codes <- c(
  "Calidris bairdii"      = "BASA",
  "Haematopus palliatus"  = "AMOY",
  "Numenius phaeopus"     = "WHIM",
  "Limosa haemastica"     = "HUGO",
  "Tringa flavipes"       = "LEYE",
  "Tringa melanoleuca"    = "GRYE"
)

# Renombrar las filas de y con los códigos de las especies
rownames(data_list$y) <- species_codes[rownames(data_list$y)]

site_names <- colnames(data_list$y) 

for (i in names(data_list$covs)) {
  x <- data_list$covs[[i]]
  x <- matrix(x, ncol = 1) 
  rownames(x) <- site_names 
  colnames(x) <- i
  data_list$covs[[i]] <- x
}

# Convertir cada covariable de matriz a vector
data_list$covs <- lapply(data_list$covs, function(x) {
  if (is.matrix(x) && ncol(x) == 1) {
    as.vector(x)
  } else {
    x
  }
})

# Para evitar autocorrelación temporal incluimos el año como una variable categórica y no numérica
data_list$covs$year <- as.factor(data_list$covs$year)

# Revisamos
str(data_list)
```

## Modelado de abunancia con GLMM

Ahora que tenemos nuestros datos preparados, vamos a construir un modelo estadístico para estimar abundancias por año y la tendencia de las aves playeras seleccionadas. Utilizaremos un Modelo Linear Generalizado Mixto (GLMM) bayesiano que puede manejar datos de conteo con muchos ceros y sobredispersión.

Preparación del modelo

```{r modelo}
# Obtener el número de especies para configurar el modelo
n.sp <- dim(data_list$y)[1]

# Configuración de Valores Iniciales. Los valores iniciales son el "punto de partida" desde donde el modelo "busca" el valor real de cada parametro estimado.
# Estos valores pueden ser modificados para optimizar el modelo de acuerdo a información previa o en el contexto de una hipótesis específica.
ms.inits <- list(
  beta.comm = 0, #Efecto promedio a nivel de comunidad
  beta = 0, #Efectos específicos por especie  
  tau.sq.beta = 1, #Variabilidad entre especies
  kappa = 1, #Parámetro de dispersión
  sigma.sq.mu = 0.5 #Variabilidad en las abundancias medias
)

# Configuración de distribuciones previas. Estas representan nuestro conocimiento inicial sobre los parámetros. 
ms.priors <- list(
  # Prior para efectos de comunidad: normal con media 0 y varianza grande (poco informativo)
  beta.comm.normal = list(mean = 0, var = 100),
  
  # Prior para variabilidad entre especies: gamma inversa poco informativa
  tau.sq.beta.ig = list(a = 0.1, b = 0.1),
  
  # Prior para variabilidad de abundancias: gamma inversa poco informativa  
  sigma.sq.mu.ig = list(a = 0.1, b = 0.1),
  
  # Prior para parámetro de dispersión: uniforme entre 0 y 100
  kappa.unif = list(a = 0, b = 100)
)

# Configuración de parámetros de muestreo. Estos controlan cómo el modelo explora el espacio de parámetros (Valores más altos = pasos más grandes, valores más bajos = pasos más pequeños).
ms.tuning <- list(
  beta = 0.2, #Tamaño de paso para efectos de especies
  beta.star = 0.3, #Tamaño de paso para nuevos efectos
  kappa = 0.3 #Tamaño de paso para dispersión
)

# Modelo nulo 
# El modelo nulo incluye solo el parametro de intercepto (~ 1). Se asume que la abundancia es constante para todas las especies a través del tiempo y entre esquemas de monitoreo. Es nuestro "modelo base", el más simple.
out.0 <- msAbund(
  formula = ~ 1, 
  data = data_list,
  inits = ms.inits,
  n.batch = 2100, #Número de lotes a procesar
  tuning = ms.tuning,
  batch.length = 25, #Iteraciones por lote 
  family = 'NB', #Binomial Negativa para datos de conteo con sobredispersión
  priors = ms.priors,
  n.omp.threads = 1, #Número de hilos de procesamiento
  verbose = TRUE, #Nos muestra el progreso, para omitirlo cambiar por FALSE
  n.report = 200, #Reportar progreso cada 200 iteraciones       
  n.burn = 30000, #Iteraciones de "calentamiento" (se descartan)        
  n.thin = 30, #Tomamos 1 de cada 30 iteraciones (reduce autocorrelación)           
  n.chains = 4 #Número de cadenas independientes (para verificar convergencia)          
)

# Resumen de los resultados del modelo nulo
summary(out.0)

# Modelo completo
# El modelo completo incluye las covariables que seleccionemos (en este caso: ~ MSP + CNAA + CCAP + year), lo que le permite capturar diferencias entre esquemas de monitoreo y tendencias temporales.
out.mod <- msAbund(
  formula = ~ MSP + CNAA + CCAP + year, #Los tres esquemas y el año como variables fijas 
  data = data_list,
  inits = ms.inits,
  n.batch = 2100, #Número de lotes a procesar
  tuning = ms.tuning,
  batch.length = 25, #Iteraciones por lote 
  family = 'NB', #Binomial Negativa para datos de conteo con sobredispersión
  priors = ms.priors,
  n.omp.threads = 1, #Número de hilos de procesamiento
  verbose = TRUE, #Nos muestra el progreso, para omitirlo cambiar por FALSE
  n.report = 200, #Reportar progreso cada 200 iteraciones       
  n.burn = 30000, #Iteraciones de "calentamiento" (se descartan)        
  n.thin = 30, #Tomamos 1 de cada 30 iteraciones (reduce autocorrelación)           
  n.chains = 4 #Número de cadenas independientes (para verificar convergencia)          
)

# Resumen de los resultados del modelo completo
summary(out.mod)

# Comparación de Modelos: Modelo Completo (out.mod) vs Modelo Nulo (out.0)

# Para evaluar si las covariables incluidas en el modelo completo realmente mejoran nuestras predicciones, comparamos los modelos mediante el estadístico WAIC (Widely Applicable Information Criterion). 
# WAIC es una medida que balanza el ajuste del modelo con su complejidad. Valores más BAJOS de WAIC un mejor ajuste del modelo a los datos.

# Calculamos WAIC para ambos modelos
waicAbund(out.0)
waicAbund(out.mod)

```

# Diagnosticos del Modelo

Una vez ejecutado los modelos, es importante verificar que funcionó correctamente. Los diagnósticos nos permiten evaluar si nuestras estimaciones son confiables.
Utilizamos dos diagnósticos que nos ayudan a entender:

1. **Verificación Predictiva Posterior**: Si el modelo replica bien los datos observados.
2. **Residuales**: Si hay patrones no explicados por el modelo.

```{r diagnosticos}
# 1. Posterior Predictive Check (PPC). Este análisis compara los datos observados con las que predice el modelo
verificacion_predictiva <- ppcAbund(out.mod, fit.stat = 'freeman-tukey', group = 0)
print(summary(verificacion_predictiva)) # Si el valor de Bayesian p-value está entre 0.3 y 0.7, el ajuste del modelo se considera aceptable.

# 2. Análisis de residuales. Los residuales son las diferencias entre los valores  observado y los predichos
# Obtener valores ajustados (predicciones del modelo)
valores_ajustados <- fitted(out.mod)
promedio_ajustado <- apply(valores_ajustados, 2, mean)

# Preparar datos para el análisis de residuales
datos_observados <- as.vector(data_list$y)
valores_predichos <- rep(promedio_ajustado, each = nrow(data_list$y))

# Filtrar solo valores válidos (sin NA y valores predichos > 0)
indices_validos <- !is.na(datos_observados) & !is.na(valores_predichos) & valores_predichos > 0
obs_validos <- datos_observados[indices_validos]
pred_validos <- valores_predichos[indices_validos]

# Verificar que tenemos datos válidos
if (length(obs_validos) == 0) {
  cat("⚠ No hay datos válidos para calcular residuales.\n")
} else {
  cat("Analizando", length(obs_validos), "observaciones válidas...\n")
  
  # Calcular residuales de Pearson (estandarizados) de forma más robusta
  # Agregamos un pequeño valor para evitar divisiones problemáticas
  pred_validos_seguro <- pmax(pred_validos, 0.001)
  residuales <- (obs_validos - pred_validos) / sqrt(pred_validos_seguro)
  
  # Remover valores extremos o problemáticos
  residuales_limpios <- residuales[is.finite(residuales) & !is.na(residuales)]
  
  if (length(residuales_limpios) == 0) {
    cat("⚠ No se pudieron calcular residuales válidos.\n")
  } else {
    cat("Resumen de residuales (", length(residuales_limpios), "valores):\n")
    cat("  Mínimo:", round(min(residuales_limpios, na.rm = TRUE), 3), "\n")
    cat("  1er Cuartil:", round(quantile(residuales_limpios, 0.25, na.rm = TRUE), 3), "\n")
    cat("  Mediana:", round(median(residuales_limpios, na.rm = TRUE), 3), "\n")
    cat("  Media:", round(mean(residuales_limpios, na.rm = TRUE), 3), "\n")
    cat("  3er Cuartil:", round(quantile(residuales_limpios, 0.75, na.rm = TRUE), 3), "\n")
    cat("  Máximo:", round(max(residuales_limpios, na.rm = TRUE), 3), "\n")
    
    # Actualizar la variable residuales para usar en los gráficos
    residuales <- residuales_limpios
  }
}

# Gráficos del diagnóstico 
# Para los gráficos de residuales, necesitamos emparejar correctamente los datos
indices_finales <- !is.na(datos_observados) & !is.na(valores_predichos) & 
                   valores_predichos > 0.001 & is.finite((datos_observados - valores_predichos) / sqrt(valores_predichos))

obs_finales <- datos_observados[indices_finales]
pred_finales <- valores_predichos[indices_finales]
residuales_finales <- (obs_finales - pred_finales) / sqrt(pred_finales)

# Configuramos la ventana gráfica para mostrar los 3 gráficos en una cuadrícula de 2x2
par(mfrow = c(2, 2), mar = c(4, 4, 3, 2))

# Gráfico 1: Residuales vs Valores Ajustados
# Los puntos deben estar dispersos aleatoriamente alrededor de la línea roja (y=0). Patrones indican problemas del modelo.
plot(pred_finales, residuales_finales, 
         main = "Residuales vs Valores Ajustados",
         xlab = "Valores Ajustados", 
         ylab = "Residuales de Pearson",
         pch = 16, col = rgb(0, 0, 1, 0.6)) +
  abline(h = 0, col = "red", lty = 2, lwd = 2) 

# Gráfico 2: Q-Q plot (comparación con distribución normal)
# Los puntos deben seguir la línea roja. Desviaciones indican que los residuales no siguen una distribución normal
qqnorm(residuales_finales, main = "Q-Q Plot de Residuales",
         pch = 16, col = rgb(0, 0, 1, 0.6))
qqline(residuales_finales, col = "red", lwd = 2)
  
# Gráfico 3: Histograma de residuales
# Debe parecerse a una campana (distribución normal)
hist(residuales, main = "Distribución de Residuales", 
    xlab = "Residuales de Pearson", 
    col = rgb(0.7, 0.9, 1, 0.7), border = "black", 
    breaks = min(30, max(5, length(residuales)/20)))  # Ajustar número de breaks
  
  # Agregar curva normal teórica
  x_norm <- seq(min(residuales), max(residuales), length = 100)
  y_norm <- dnorm(x_norm, mean(residuales), sd(residuales))
  y_norm <- y_norm * length(residuales) * diff(range(residuales)) / 
              min(30, max(5, length(residuales)/20))
  lines(x_norm, y_norm, col = "red", lwd = 2)

# Restaurar configuración gráfica
par(mfrow = c(1, 1))

```

# Limitaciones del Modelo y Consideraciones Importantes

Los gráficos de diagnóstico revelan algunas limitaciones importantes en nuestro modelo. Al observar los gráficos de diagnóstico, podemos identificar:

Gráfico 1.- Residuales vs Valores Ajustados: Los puntos no se distribuyen aleatoriamente alrededor de la línea roja (y=0).

Gráfico 2.- Q-Q plot (comparación con distribución normal): Los puntos se desvían de la línea roja, especialmente en los extremos.

Gráfico 3.- Histograma de residuales: La distribución no es normal, hay asimetría.

Este histograma nos dice que nuestro modelo tiene un problema:
- Está prediciendo más aves de las que realmente observamos
- Los residuales deberían estar centrados en cero, pero están sesgados
- Esto sugiere que necesitamos mejorar el modelo

Problemas identificados:
- Sobredispersión: La variabilidad real es mayor que la asumida por el modelo
- Heterocedasticidad: La varianza no es constante a través de los valores predichos
- No normalidad: Los residuales no siguen una distribución normal

# Posible soluciones y mejoras al modelo

Para mejorar algunos de los problemas mencionados creemos que puede ser relevante incluir variables ambientales como factores climáticos (temperatura, precipitación), hábitat (superficie o tipo de sustrato), factores antropogénicos (pertubaciones o cercanía a ciudades) o incluso ciclos periódicos, como el fenómeno El Niño/La Niña.

Además debemos considerar cambiar la familia de distribución usada (Binomial Negativa) por una cero inflado, como la Binomial Negativo Cero Inflado, por la características de los datos (sobredispersión y exceso de ceros). Sin embargo, el paquete spAbundance actualmente solo permite el uso de las familias 'NB' (binomial negativo), 'Poisson', 'Gaussian' y 'zi-Gaussian'. Esperamos que el desarrollo de este paquete aún reciente extienda sus capacidades para permitir la distribución Binomial Negtivo Cero Inflado.


# Visualización de Resultados

Una vez que tenemos nuestro modelo ajustado, es importante extraer y visualizar los resultados de manera comprensible. En esta sección crearemos tablas resumen y gráficos que nos ayuden a interpretar las abundancias estimadas y las tendencias temporales.

El modelo nos proporciona estimaciones de abundancia para cada combinación de sitio, año y especie. Necesitamos extraer esta información y organizarla de manera clara.

```{r resultados}
#Creamos las carpetas en las que guardaremos los resultados
dir.create("resultados_abundancia", showWarnings = FALSE)
dir.create("resultados_abundancia/tablas", showWarnings = FALSE)
dir.create("resultados_abundancia/graficos", showWarnings = FALSE)

# Extraemos la información básica de nuestros datos originales
site_year_names <- colnames(y_filtrado)  # Nombres de sitio.año 
sitios <- sub("\\..*", "", site_year_names)  # Extraemos el nombre del sitio
años <- as.numeric(sub(".*\\.", "", site_year_names))  # Extraemos el año

# Obtenemos las abundancias estimadas del modelo (muestras posteriores)
mu_samples <- fitted(out.mod)  # Función que extrae las estimaciones del modelo

# Dimensiones de nuestros resultados
n_samples <- dim(mu_samples)[1]  # Número de muestras de la distribución posterior
n_species <- dim(mu_samples)[2]  # Número de especies (6 en el caso de estos datos)
n_obs     <- dim(mu_samples)[3]  # Número de observaciones (combinaciones de sitio-año)

# Recuperamos el nombre de las especies 
species_names <- rownames(data_list$y)

# Creamos un dataframe completo, con todas las combinaciones, esto nos ayudará a organizar mejor los resultados
mu_df_completo <- expand.grid(
  muestra = 1:n_samples,        # Cada muestra de la distribución posterior
  obs_idx = 1:n_obs,           # Cada observación (sitio-año)
  especie = species_names,      # Cada especie
  stringsAsFactors = FALSE
)

# Agregamos las abundancias estimadas y la información adicional
mu_df_completo$abundancia <- as.vector(mu_samples)
mu_df_completo$sitio_año <- rep(rep(site_year_names, each = n_samples), times = n_species)
mu_df_completo$sitio <- rep(rep(sitios, each = n_samples), times = n_species)
mu_df_completo$año <- rep(rep(años, each = n_samples), times = n_species)

# Lista de sitios únicos para los gráficos 
sitios_unicos <- unique(mu_df_completo$sitio)
```

Además de capturar las estimaciones de abundancia que nos proporciona el modelo, calcularemos tendencias temporales de la especies en los sitios.
Calcularemos tres tipos de tendencias:
1.- **Pendiente de regresión lineal**: Cambio promedio por año (individuos/año)
2.- **Tasa de crecimiento anual promedio**: Cambio porcentual promedio año a año
3.- **Cambio total en el periodo**: Cambio porcentual desde inicio a final

```{r calculo tendencias}
# Función para calcular tendencias temporales
calcular_tendencias <- function(data, especie_nombre, sitio_nombre = NULL) {
  
  # Si se especifica sitio, filtrar por sitio y especie; si no, solo por especie
  if(!is.null(sitio_nombre)) {
    data_filtrada <- data[data$especie == especie_nombre & data$sitio == sitio_nombre, ]
    nombre_grupo <- paste(especie_nombre, "-", sitio_nombre)
  } else {
    # Para análisis poblacional (todos los sitios)
    data_filtrada <- data[data$especie == especie_nombre, ]
    # Sumar abundancias de todos los sitios por año y muestra
    data_filtrada <- data_filtrada %>%
      group_by(muestra, año) %>%
      summarise(abundancia = sum(abundancia), .groups = 'drop')
    nombre_grupo <- paste(especie_nombre, "- Poblacional")
  }
  
  if(nrow(data_filtrada) == 0) {
    return(NULL)
  }
  
  # Calcular tendencias para cada muestra del modelo bayesiano
  tendencias_por_muestra <- data_filtrada %>%
    group_by(muestra) %>%
    arrange(año) %>%
    summarise(
      # 1. Pendiente de regresión lineal (cambio promedio por año)
      pendiente_regresion = {
        if(n() > 2) {
          modelo_lineal <- lm(abundancia ~ año)
          coef(modelo_lineal)[2]  # Pendiente
        } else {
          NA
        }
      },
      
      # 2. Tasa de crecimiento anual promedio
      tasa_crecimiento_promedio = {
        if(n() > 1) {
          abundancias <- abundancia[order(año)]
          años_ord <- sort(año)
          # Calcular tasas de crecimiento año a año
          tasas_anuales <- numeric()
          for(i in 2:length(abundancias)) {
            if(abundancias[i-1] > 0) {  # Evitar división por cero
              tasa <- (abundancias[i] - abundancias[i-1]) / abundancias[i-1]
              tasas_anuales <- c(tasas_anuales, tasa)
            }
          }
          if(length(tasas_anuales) > 0) {
            mean(tasas_anuales)
          } else {
            NA
          }
        } else {
          NA
        }
      },
      
      # 3. Cambio total en el periodo (abundancia final / abundancia inicial)
      cambio_total = {
        if(n() > 1) {
          abundancias <- abundancia[order(año)]
          if(abundancias[1] > 0) {
            (abundancias[length(abundancias)] - abundancias[1]) / abundancias[1]
          } else {
            NA
          }
        } else {
          NA
        }
      },
      
      años_monitoreados = n(),
      abundancia_inicial = abundancia[which.min(año)],
      abundancia_final = abundancia[which.max(año)],
      .groups = 'drop'
    )
  
  # Calcular estadísticas resumen de las tendencias
  resumen_tendencias <- tendencias_por_muestra %>%
    summarise(
      grupo = nombre_grupo,
      años_total = max(años_monitoreados),
      
      # Estadísticas de la pendiente de regresión
      pendiente_media = mean(pendiente_regresion, na.rm = TRUE),
      pendiente_ic_inf = quantile(pendiente_regresion, 0.025, na.rm = TRUE),
      pendiente_ic_sup = quantile(pendiente_regresion, 0.975, na.rm = TRUE),
      
      # Estadísticas de la tasa de crecimiento anual
      tasa_crecimiento_media = mean(tasa_crecimiento_promedio, na.rm = TRUE),
      tasa_crecimiento_ic_inf = quantile(tasa_crecimiento_promedio, 0.025, na.rm = TRUE),
      tasa_crecimiento_ic_sup = quantile(tasa_crecimiento_promedio, 0.975, na.rm = TRUE),
      
      # Estadísticas del cambio total
      cambio_total_medio = mean(cambio_total, na.rm = TRUE),
      cambio_total_ic_inf = quantile(cambio_total, 0.025, na.rm = TRUE),
      cambio_total_ic_sup = quantile(cambio_total, 0.975, na.rm = TRUE),
      
      # Interpretación de la tendencia
      interpretacion = case_when(
        pendiente_ic_sup < 0 ~ "Declive significativo",
        pendiente_ic_inf > 0 ~ "Crecimiento significativo", 
        TRUE ~ "Sin tendencia clara, el IC incluye el cero" # no podemos descartar que la tendencia sea cero
      )
    )
  
  return(list(
    resumen = resumen_tendencias,
    muestras = tendencias_por_muestra
  ))
}
```

Creamos tablas que resumen nuestros resultados.

```{r tablas}
# Tabla 1: Abundancias estimadas por sitio-especie-año
resumen_estimaciones <- mu_df_completo %>%
  group_by(sitio, especie, año) %>%
  summarise(
    # Medidas de tendencia central
    abundancia_media = round(mean(abundancia), 2),
    abundancia_mediana = round(median(abundancia), 2),
    
    # Medida de dispersión
    desviacion_std = round(sd(abundancia), 2),
    
    # Intervalos de credibilidad (equivalente bayesiano de intervalos de confianza)
    ic_inferior_95 = round(quantile(abundancia, 0.025), 2),  # Límite inferior 95%
    ic_superior_95 = round(quantile(abundancia, 0.975), 2),  # Límite superior 95%
    ic_inferior_50 = round(quantile(abundancia, 0.25), 2),   # Límite inferior 50%
    ic_superior_50 = round(quantile(abundancia, 0.75), 2),   # Límite superior 50%
    .groups = 'drop'
  ) %>%
  arrange(sitio, especie, año)  # Ordenar por sitio, especie y año

# Tabla 2: Datos observados originales

datos_observados_long <- data.frame()  # Data frame vacío para llenar

# Recorremos cada especie (filas de la matriz)
for(i in 1:nrow(data_list$y)) {
  especie_nombre <- rownames(data_list$y)[i]
  
  # Recorremos cada sitio-año (columnas de la matriz)
  for(j in 1:ncol(data_list$y)) {
    sitio_año <- site_year_names[j]
    sitio <- sitios[j]
    año <- años[j]
    abundancia_obs <- data_list$y[i, j]  # Valor observado
    
    # Solo incluir valores que no sean NA
    if(!is.na(abundancia_obs)) { 
      datos_observados_long <- rbind(datos_observados_long, 
                                   data.frame(
                                     sitio = sitio,
                                     especie = especie_nombre,
                                     año = año,
                                     abundancia_observada = abundancia_obs
                                   ))
    }
  }
}

# Tabla 3: Comparación entre datos observados y estimados
comparacion_completa <- merge(
  datos_observados_long, 
  resumen_estimaciones, 
  by = c("sitio", "especie", "año"),  # Variables para hacer la unión
  all = TRUE  # Mantener todas las filas
)

# Agregar columnas que evalúan si los datos observados caen dentro de los intervalos
comparacion_completa <- comparacion_completa %>%
  mutate(
    # ¿El valor observado está dentro del intervalo del 95%?
    dentro_ic_95 = abundancia_observada >= ic_inferior_95 & abundancia_observada <= ic_superior_95,
    # ¿El valor observado está dentro del intervalo del 50%?
    dentro_ic_50 = abundancia_observada >= ic_inferior_50 & abundancia_observada <= ic_superior_50
  ) %>%
  arrange(sitio, especie, año)

# Guardamos todas las tablas en un archivo Excel, una tabla por hoja
write_xlsx(
  list(
    "Resumen_Estimaciones" = resumen_estimaciones,
    "Datos_Observados" = datos_observados_long,
    "Comparacion_Completa" = comparacion_completa
  ),
  path = "resultados_abundancia/tablas/resumen_general_abundancia.xlsx"
)

# Crear una tabla resumen
resumen_compacto <- comparacion_completa %>%
  group_by(sitio, especie) %>%
  summarise(
    años_monitoreados = n(),  # Cuántos años tenemos datos
    abundancia_obs_promedio = round(mean(abundancia_observada, na.rm = TRUE), 1),
    abundancia_est_promedio = round(mean(abundancia_media, na.rm = TRUE), 1),
    observaciones_en_ic95 = sum(dentro_ic_95, na.rm = TRUE),  # Cuántas obs. caen en el IC95%
    porcentaje_en_ic95 = round(100 * sum(dentro_ic_95, na.rm = TRUE) / n(), 1),  # % de acierto
    .groups = 'drop'
  ) %>%
  arrange(sitio, especie)

# Guardamos la tabla resumen compacta
write_xlsx(resumen_compacto, "resultados_abundancia/tablas/resumen_compacto.xlsx")
```

Los gráficos nos ayudan a visualizar las tendencias temporales y la variabilidad en las estimaciones de abundancia. 
Primero generaremos gráficos para los diferentes sitios monitoreados.

```{r gráficos por sitio}
# Gráficos por sitio. Esta función genera un gráfico con boxplots mostrando la distribución de abundancias estimadas
grafico_sitio <- function(sitio_nombre, data = mu_df_completo) {
  # Filtrar datos solo para el sitio específico
  data_sitio <- data[data$sitio == sitio_nombre, ]
  
  # Crear el gráfico
  ggplot(data_sitio, aes(x = as.factor(año), y = abundancia, fill = as.factor(año))) +
    # Boxplots para mostrar la distribución de abundancias estimadas
    geom_boxplot(alpha = 0.6,           # Transparencia
                color = "black",        # Color del borde
                outlier.shape = 21,     # Forma de los valores atípicos
                outlier.size = 1.5) +   # Tamaño de los valores atípicos
    
    # Separar por especie en paneles diferentes
    facet_wrap(~ especie, scales = "free_y") +  # "free_y" permite escalas Y independientes
    
    # Tema y estética
    theme_minimal() +
    theme(
      strip.text = element_text(size = 12, family = "Times", face = "bold"),
      axis.text = element_text(size = 10, family = "Times"),
      axis.title = element_text(size = 12, family = "Times"),
      plot.title = element_text(size = 14, hjust = 0.5, family = "Times"),
      legend.position = "none"  
    ) +
    
    # Etiquetas del gráfico
    labs(
      x = "Año",
      y = "Número de Individuos Estimados",
      title = paste("Estimaciones de Abundancia - Sitio:", sitio_nombre)
    ) +
    
    # Paleta de colores
    scale_fill_brewer(palette = "Blues", name = "Año")
}


# Para observar mejor los resultados generaremos gráficos sin outliers. Los outliers pueden influir en la escala del gráfico lo que puede dificultar observar el "grueso" de los resultados.

# Esta función crea una versión "limpia" que facilita la interpretación visual.
grafico_sitio2 <- function(sitio_nombre, data = mu_df_completo, guardar = TRUE) {
  # Filtar datos para cada sitio
  data_sitio <- data[data$sitio == sitio_nombre, ]
  # Calcular estadísticas por especie y año
  stats_sitio <- data_sitio %>%
    group_by(especie, año) %>%
    summarise(
      media = mean(abundancia),
      mediana = median(abundancia),
      q25 = quantile(abundancia, 0.25),
      q75 = quantile(abundancia, 0.75),
      ic_inf = quantile(abundancia, 0.025),
      ic_sup = quantile(abundancia, 0.975),
      .groups = 'drop'
    )
  # Determinar el límite superior para cada especie (evita que outliers compriman la escala)
  # Usamos el mayor valor entre Q3 e IC superior, más un 10% de margen
  y_max_por_especie <- stats_sitio %>%
    group_by(especie) %>%
    summarise(ymax_custom = max(q75, ic_sup, na.rm = TRUE) * 1.1)  # 10% margen
  
  # Filtrar datos eliminando valores que excedan estos límites
  data_filtrada <- data_sitio %>%
    left_join(y_max_por_especie, by = "especie") %>%
    filter(abundancia <= ymax_custom)
 
  # Crear el gráfico 
  p <- ggplot(data_filtrada, aes(x = as.factor(año), y = abundancia, fill = as.factor(año))) +
    # Boxplots sin mostrar outliers (outlier.shape = NA los oculta)
    geom_boxplot(alpha = 0.6, color = "black", outlier.shape = NA) +
    
    # Agregar barras de error mostrando intervalos de confianza
    geom_errorbar(data = stats_sitio, 
                  aes(x = as.factor(año), ymin = ic_inf, ymax = ic_sup),
                  width = 0.2, color = "grey10", linewidth = 0.8, alpha = 0.7,
                  inherit.aes = FALSE) +
    
    facet_wrap(~ especie, scales = "free_y", ncol = 3) +
    theme_minimal() +
    theme(
      strip.text = element_text(size = 12, family = "Times", face = "bold"),
      axis.text.x = element_text(size = 10, family = "Times", angle = 45, hjust = 1),
      axis.text.y = element_text(size = 10, family = "Times"),
      axis.title = element_text(size = 12, family = "Times"),
      plot.title = element_text(size = 14, hjust = 0.5, family = "Times", face = "bold"),
      plot.subtitle = element_text(size = 11, hjust = 0.5, family = "Times"),
      plot.caption = element_text(size = 9, family = "Times", hjust = 0),
      legend.position = "none"
    ) +
    labs(
      x = "Año",
      y = "Número de Individuos Estimados",
      title = "Abundancia Estimada por Especie (sin outliers)",
      subtitle = paste("Sitio:", sitio_nombre),
      caption = "Cajas: Q1-Q3 | Línea: mediana | Barras: IC 95%"
    ) +
    scale_fill_brewer(palette = "Set3", name = "Año")
  return(p)
}

# Generamos los gráficos para todos los sitios
for(sitio in sitios_unicos) {
  print(paste("Creando gráfico para:", sitio))
  
  # Crear el gráfico
  p1 <- grafico_sitio(sitio)
  
  # Crear el gráfico sin outlyers
  p2 <- grafico_sitio2(sitio)
  
  # Guarda el gráfico
  nombre_archivo1 <- paste0("resultados_abundancia/graficos/abundancia_", sitio, ".png")
  ggsave(nombre_archivo1, p1, width = 12, height = 8, dpi = 300)
  
  nombre_archivo2 <- paste0("resultados_abundancia/graficos/abundancia2_", sitio, ".png")
  ggsave(nombre_archivo2, p2, width = 12, height = 8, dpi = 300)
}

```

Además generaremos gráficos para las especies. En este caso, un panel de 9 gráficos por especie, uno por cada sitio monitoreado, y un gráfico general de estimación de abundancia para cada especie, considerando todos los sitios. 

```{r gráficos por especie}
# Función para crear gráficos de evolución temporal y tendencia por sitio para una especie específica. Estos gráficos nos permiten visualizar cómo cambia la abundancia de una especie en un sitio particular.
grafico_especie_con_tendencia <- function(especie_nombre, sitio_nombre, data = mu_df_completo) {
  # Filtrar datos solo para la combinación específica de especie y sitio    
  # Esto puede ocurrir cuando una especie no ha sido observada en un sitio específico  
  data_filtrada <- data[data$especie == especie_nombre & data$sitio == sitio_nombre, ]
  
  # Si no hay datos para esta combinación, devolver NULL
  if(nrow(data_filtrada) == 0) {
    return(NULL) 
  }
  
  # Calcular estadísticas resumen por año
  stats_datos <- data_filtrada %>%
    group_by(año) %>%
    summarise(
      media = mean(abundancia), # Abundancia promedio estimada 
      mediana = median(abundancia), # Mediana
      ic_inf_95 = quantile(abundancia, 0.025), # Límite inferior intervalo 95%
      ic_sup_95 = quantile(abundancia, 0.975), # Límite superior intervalo 95%
      .groups = 'drop'
    )
  
  # Calcular tendencias estadísticas para este sitio específico
  tendencia_sitio <- calcular_tendencias(data, especie_nombre, sitio_nombre)
  
  # Crear el gráfico base
  p <- ggplot(stats_datos, aes(x = año)) +
    # Banda gris: zona de incertidumbre (95% de los datos)
    geom_ribbon(aes(ymin = ic_inf_95, ymax = ic_sup_95), alpha = 0.2, fill = "darkgray") +
    # Línea azul: evolución de la abundancia media a través del tiempo
    geom_line(aes(y = media), color = "darkblue", linewidth = 1.5)
  
  # Agregar línea de tendencia estadística si tenemos datos suficientes
  if(!is.null(tendencia_sitio) && !is.na(tendencia_sitio$resumen$pendiente_media)) {
    # Calcular línea de regresión
    años_seq <- seq(min(stats_datos$año), max(stats_datos$año), length.out = 100)
    # Y = intercepto + pendiente * X
    # Necesitamos calcular el intercepto usando el punto medio
    año_medio <- mean(stats_datos$año)
    abundancia_media <- mean(stats_datos$media)
    intercepto <- abundancia_media - tendencia_sitio$resumen$pendiente_media * año_medio
    
    linea_tendencia <- data.frame(
      año = años_seq,
      tendencia = intercepto + tendencia_sitio$resumen$pendiente_media * años_seq
    )
    
    # Agregar línea de tendencia
    p <- p + geom_line(data = linea_tendencia, aes(x = año, y = tendencia), 
                      color = "darkgreen", linetype = "dashed", linewidth = 1, alpha = 0.8)
  }
  
  # Crear título con información de tendencia
  if(!is.null(tendencia_sitio)) {
    pendiente <- round(tendencia_sitio$resumen$pendiente_media, 3)
    tasa_crecimiento <- round(tendencia_sitio$resumen$tasa_crecimiento_media * 100, 1)
    interpretacion <- tendencia_sitio$resumen$interpretacion
    
    titulo_sitio <- paste0(sitio_nombre, "\n", 
                          interpretacion)
  } else {
    titulo_sitio <- sitio_nombre
  }
  
  p <- p + theme_minimal() +
    theme(
      axis.text = element_text(size = 8, family = "Times"),
      axis.title = element_text(size = 9, family = "Times"),
      plot.title = element_text(size = 9, hjust = 0.5, family = "Times", face = "bold"),
      axis.title.x = element_blank(),
      plot.margin = margin(5,5,5,5)
    ) +
    labs(
      y = "Abundancia estimada",
      title = titulo_sitio
    ) +
    scale_x_continuous(breaks = pretty_breaks(n = 6)) + 
    scale_y_continuous(labels = comma_format())
  
  return(p)
}

# Panel mejorado con tendencias incluidas
panel_con_tendencias <- function(especie_nombre, data = mu_df_completo, guardar = TRUE) {
  
  plots_sitios <- list()
  
  for(sitio in sitios_unicos) {
    p_sitio <- grafico_especie_con_tendencia(especie_nombre, sitio, data)
    if(!is.null(p_sitio)) {
      plots_sitios[[sitio]] <- p_sitio
    } else {
      plots_sitios[[sitio]] <- ggplot() + 
        annotate("text", x = 0.5, y = 0.5, label = "Sin datos", size = 4, color = "gray50") +
        theme_void() +
        theme(plot.title = element_text(size = 11, hjust = 0.5, family = "Times", face = "bold")) +
        ggtitle(sitio)
    }
  }
  
  titulo_panel <- paste("Evolución y Tendencias por Sitio -", especie_nombre)
  subtitulo_panel <- "Línea azul: abundancia media | Banda gris: IC 95% | Línea verde discontinua: tendencia"
  
  # Combinar todos los gráficos en un solo panel organizado en cuadrícula 3x3
  panel <- grid.arrange(
    grobs = plots_sitios,
    ncol = 3,
    top = textGrob(titulo_panel, gp = gpar(fontsize = 16, fontface = "bold", fontfamily = "Times")),
    bottom = textGrob(subtitulo_panel, gp = gpar(fontsize = 10, fontfamily = "Times", col = "gray40"))
  )
  
  if(guardar) {
    ggsave(
      filename = paste0("resultados_abundancia/por_especie/", especie_nombre, "/evolucion_tendencias_sitios_", especie_nombre, ".png"),
      plot = panel,
      width = 15, height = 12, dpi = 300, bg = "white"
    )
  }
  
  return(panel)
}

# Función para crear gráficos de tendencia temporal para cada especie. Estos gráficos nos permiten visualizar cómo cambia la abundancia de una especie considerando los 9 sitios monitoreados. Esta función suma las abundancias de todos los sitios para obtener una "estimación de la población local" de cada especie.

estpob_con_tendencias <- function(especie_nombre, data = mu_df_completo, guardar = TRUE) {
  
  data_especie <- data[data$especie == especie_nombre, ]
  # Calcular la abundancia total por año sumando todos los sitios
  estimacion_poblacional <- data_especie %>%
    group_by(muestra, año) %>%
    summarise(abundancia_total = sum(abundancia), .groups = 'drop') %>%
    # Calculamos estadísticas resumen por año
    group_by(año) %>%
    summarise(
      media_poblacion = mean(abundancia_total),
      mediana_poblacion = median(abundancia_total),
      ic_inf_95 = quantile(abundancia_total, 0.025),
      ic_sup_95 = quantile(abundancia_total, 0.975),
      .groups = 'drop'
    )
  
  # Calcular tendencias poblacionales
  tendencia_poblacional <- calcular_tendencias(data, especie_nombre, sitio_nombre = NULL)
  
  # Crear gráfico base
  p_poblacional <- ggplot(estimacion_poblacional, aes(x = año)) +
    # Banda gris: zona de incertidumbre (95% de los datos)
    geom_ribbon(aes(ymin = ic_inf_95, ymax = ic_sup_95), alpha = 0.2, fill = "darkgray") +
    # Línea azul: evolución de la abundancia media a través del tiempo
    geom_line(aes(y = media_poblacion), color = "darkblue", linewidth = 2)
  
  # Agregar línea de tendencia estadística si tenemos datos suficientes
  if(!is.null(tendencia_poblacional) && !is.na(tendencia_poblacional$resumen$pendiente_media)) {
    # Calcular línea de regresión
    años_seq <- seq(min(estimacion_poblacional$año), max(estimacion_poblacional$año), length.out = 100)
    # Y = intercepto + pendiente * X
    año_medio <- mean(estimacion_poblacional$año)
    abundancia_media <- mean(estimacion_poblacional$media_poblacion)
    intercepto <- abundancia_media - tendencia_poblacional$resumen$pendiente_media * año_medio
    
    linea_tendencia <- data.frame(
      año = años_seq,
      tendencia = intercepto + tendencia_poblacional$resumen$pendiente_media * años_seq
    )
    
    # Agregar línea de tendencia
    p_poblacional <- p_poblacional + 
      geom_line(data = linea_tendencia, aes(x = año, y = tendencia), 
               color = "darkgreen", linetype = "dashed", linewidth = 2, alpha = 0.8)
  }
  
  # Crear título y subtítulo con información de tendencias
  titulo_base <- paste("Evolución y Tendencia Poblacional -", especie_nombre)
  
  if(!is.null(tendencia_poblacional)) {
    pendiente <- round(tendencia_poblacional$resumen$pendiente_media, 2)
    tasa_crecimiento <- round(tendencia_poblacional$resumen$tasa_crecimiento_media * 100, 2)
    cambio_total <- round(tendencia_poblacional$resumen$cambio_total_medio * 100, 1)
    interpretacion <- tendencia_poblacional$resumen$interpretacion
    
    subtitulo_tendencia <- paste0("Tendencia: ", interpretacion, " | ", 
                                 pendiente, " ind/año (", tasa_crecimiento, "%/año) | ",
                                 "Cambio total: ", cambio_total, "%")
  } else {
    subtitulo_tendencia <- "Datos insuficientes para calcular tendencias"
  }
  
  p_poblacional <- p_poblacional + theme_minimal() +
    theme(
      axis.text = element_text(size = 12, family = "Times"),
      axis.title = element_text(size = 14, family = "Times"),
      plot.title = element_text(size = 16, hjust = 0.5, family = "Times", face = "bold"),
      plot.subtitle = element_text(size = 12, hjust = 0.5, family = "Times", color = "gray0"),
      plot.caption = element_text(size = 10, family = "Times", hjust = 0)
    ) +
    labs(
      x = "Año",
      y = "Abundancia Poblacional Estimada (9 sitios)",
      title = titulo_base,
      subtitle = subtitulo_tendencia,
      caption = "Línea azul: abundancia media | Banda gris: IC 95% | Línea verde discontinua: tendencia"
    ) +
    scale_x_continuous(breaks = pretty_breaks(n = 6)) +
    scale_y_continuous(labels = comma_format())
  
  if(guardar) {
    ggsave(
      filename = paste0("resultados_abundancia/por_especie/", especie_nombre, "/evolucion_tendencia_poblacional_", especie_nombre, ".png"),
      plot = p_poblacional,
      width = 12, height = 8, dpi = 300, bg = "white"
    )
  }
  
  # Devolver tanto el gráfico como los datos calculados
  return(list(
    grafico = p_poblacional, 
    datos = estimacion_poblacional,
    tendencias = tendencia_poblacional
  ))
}

# Obtener lista de especies para procesar
especies_nombres <- rownames(data_list$y)

# Creamos una carpeta para organizar los resultados por especie
dir.create("resultados_abundancia/por_especie", showWarnings = FALSE)

# Creamos una carpeta individual para cada especie
for(especie in especies_nombres) {
  dir.create(paste0("resultados_abundancia/por_especie/", especie), showWarnings = FALSE)
}

# Listas para almacenar todos los resultados generados
paneles_con_tendencias <- list()
poblacionales_con_tendencias <- list()

# Crear todos los gráficos por especie
for(i in seq_along(especies_nombres)) {
  especie <- especies_nombres[i]
  
  # Panel por sitios CON información de tendencias
  panel_sitios_tend <- panel_con_tendencias(especie, data = mu_df_completo, guardar = TRUE)
  paneles_con_tendencias[[especie]] <- panel_sitios_tend
  
  # Evolución poblacional general CON información de tendencias
  est_pobl_tend <- estpob_con_tendencias(especie, data = mu_df_completo, guardar = TRUE)
  poblacionales_con_tendencias[[especie]] <- est_pobl_tend
}

# Crear tabla resumen final con todas las tendencias poblacionales
tendencias_finales <- do.call(rbind, lapply(poblacionales_con_tendencias, function(x) {
  if(!is.null(x$tendencias)) x$tendencias$resumen else NULL
}))

if(!is.null(tendencias_finales)) {
  write_xlsx(tendencias_finales, "resultados_abundancia/tablas/tendencias_poblacionales_finales.xlsx")
}
```
